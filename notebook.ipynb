{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP74SUhfgFqwZOTAZ6eNhE/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9iXr1M9ld3U",
        "outputId": "62f28136-34ed-4596-ebee-1fdb17f560f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets librosa soundfile"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library"
      ],
      "metadata": {
        "id": "LlfSRv8vmLU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/franciscoaliss/music-instrument-stems\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuawK5sEmOsy",
        "outputId": "cc1223a9-ec28-4082-eac6-57e7562f5763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: bondantm\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/franciscoaliss/music-instrument-stems\n",
            "Downloading music-instrument-stems.zip to ./music-instrument-stems\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 912M/912M [00:04<00:00, 219MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "tCah-k5DnuYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5810903",
        "outputId": "1a4d4252-e962-4c71-c0ca-2a201793c1e2"
      },
      "source": [
        "acoustic_guitar_dir = '/content/music-instrument-stems/mega_augmented_ds/mega_augmented_ds/Acoustic Guitar'\n",
        "piano_dir = '/content/music-instrument-stems/mega_augmented_ds/mega_augmented_ds/Piano'\n",
        "\n",
        "audio_data = []\n",
        "labels = []\n",
        "\n",
        "def load_audio_data(directory, label):\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.wav'):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            try:\n",
        "                # Load audio file\n",
        "                data, sample_rate = librosa.load(filepath)\n",
        "                audio_data.append(data)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {filepath}: {e}\")\n",
        "\n",
        "load_audio_data(acoustic_guitar_dir, 'Acoustic Guitar')\n",
        "load_audio_data(piano_dir, 'Piano')\n",
        "\n",
        "# You can now process the audio_data and labels further as needed\n",
        "print(f\"Loaded {len(audio_data)} audio files.\")\n",
        "print(f\"Labels: {np.unique(labels)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2128 audio files.\n",
            "Labels: ['Acoustic Guitar' 'Piano']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vY1JpzqPtzBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be92a4ea"
      },
      "source": [
        "# Task\n",
        "Perform feature extraction, undersampling (optional), scaling, and data splitting on the audio data loaded from \"/content/music-instrument-stems/mega_augmented_ds/mega_augmented_ds/Acoustic Guitar\" and \"/content/music-instrument-stems/mega_augmented_ds/mega_augmented_ds/Piano\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ad5b42"
      },
      "source": [
        "## Feature extraction\n",
        "\n",
        "### Subtask:\n",
        "Extract relevant features from the audio data, such as Mel-Frequency Cepstral Coefficients (MFCCs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd0af9f5"
      },
      "source": [
        "**Reasoning**:\n",
        "Extract MFCC features from the loaded audio data and store the mean of the MFCCs for each audio file in a list, then convert the list to a NumPy array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36cfa5d1",
        "outputId": "05947e12-6bc5-4ddd-9ae3-9b66eed69ca1"
      },
      "source": [
        "features = []\n",
        "for data in audio_data:\n",
        "    # Extract MFCC features\n",
        "    mfccs = librosa.feature.mfcc(y=data, sr=22050) # Using default sample rate of librosa\n",
        "    # Calculate the mean of MFCCs across the time axis\n",
        "    mfccs_processed = np.mean(mfccs.T, axis=0)\n",
        "    features.append(mfccs_processed)\n",
        "\n",
        "# Convert the features list to a NumPy array\n",
        "features = np.array(features)\n",
        "\n",
        "print(f\"Extracted features shape: {features.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted features shape: (2128, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f83c4633"
      },
      "source": [
        "## Under sampling (optional)\n",
        "\n",
        "### Subtask:\n",
        "If the dataset is imbalanced, consider applying undersampling to balance the classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7defc410"
      },
      "source": [
        "**Reasoning**:\n",
        "Check the distribution of the labels to determine if undersampling is needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac2b6929",
        "outputId": "8167efed-ad44-443c-c76b-3cf67e7aa07d"
      },
      "source": [
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "print(\"Label distribution before undersampling:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "# Check for imbalance (e.g., if the ratio between the largest and smallest class is significant)\n",
        "if counts.max() / counts.min() > 1.5: # Using a threshold of 1.5 as an example for imbalance\n",
        "    print(\"\\nDataset is imbalanced, applying undersampling.\")\n",
        "    from imblearn.under_sampling import RandomUnderSampler\n",
        "    rus = RandomUnderSampler(random_state=42)\n",
        "    features_resampled, labels_resampled = rus.fit_resample(features, labels)\n",
        "    features = features_resampled\n",
        "    labels = labels_resampled\n",
        "    print(\"Label distribution after undersampling:\")\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    for label, count in zip(unique_labels, counts):\n",
        "        print(f\"{label}: {count}\")\n",
        "else:\n",
        "    print(\"\\nDataset is balanced or the imbalance is not significant enough for undersampling.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution before undersampling:\n",
            "Acoustic Guitar: 836\n",
            "Piano: 1292\n",
            "\n",
            "Dataset is imbalanced, applying undersampling.\n",
            "Label distribution after undersampling:\n",
            "Acoustic Guitar: 836\n",
            "Piano: 836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c3c2d7e"
      },
      "source": [
        "## Scaling\n",
        "\n",
        "### Subtask:\n",
        "Scale the extracted features to a standard range.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39981b2b"
      },
      "source": [
        "**Reasoning**:\n",
        "Import StandardScaler, instantiate it, fit it to the features, and transform the features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c952e02",
        "outputId": "8c25bd9a-5219-4383-c416-640225bfb9f0"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(features)\n",
        "features_scaled = scaler.transform(features)\n",
        "\n",
        "print(f\"Scaled features shape: {features_scaled.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled features shape: (1672, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d41738f7"
      },
      "source": [
        "## Data splitting\n",
        "\n",
        "### Subtask:\n",
        "Split the data into training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e5af554"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the scaled features and labels into training and testing sets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ed10641"
      },
      "source": [
        "**Reasoning**:\n",
        "Convert the labels list to a NumPy array before printing the shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvv8fNq8uoGZ",
        "outputId": "451ce367-92c7-43dd-d2a0-ef75fc6bf900"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "y_labels_array = np.array(labels)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled, y_labels_array, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (1337, 20)\n",
            "Shape of X_test: (335, 20)\n",
            "Shape of y_train: (1337,)\n",
            "Shape of y_test: (335,)\n"
          ]
        }
      ]
    }
  ]
}